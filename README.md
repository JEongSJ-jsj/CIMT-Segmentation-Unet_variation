# 


# ğŸ§  CIMT Segmentation â€” Pure Python Run Guide

This repository implements **10 U-Net-based architectures** for **Carotid Intima-Media Thickness (CIMT)** ultrasound segmentation using **only Python**, with no Conda or additional setup tools required.

---

## ğŸ“‚ Folder Structure

```
cimtseg_models_v4/
 â”œâ”€ models/               # All U-Net variants
 â”œâ”€ utils/                # Metrics, visualization, logger
 â”œâ”€ dataset.py            # Dataset loader
 â”œâ”€ train.py              # Model training script
 â”œâ”€ preprocess_full.py    # Data preprocessing pipeline
 â”œâ”€ visualize.py          # Visualization functions
 â”œâ”€ visual_test.py        # Visualization test runner
 â”œâ”€ results/              # Trained weights and logs
 â””â”€ CUBS/                 # Dataset folder (after preprocessing)
```

---

## âš™ï¸ 1. Install Requirements

Make sure Python â‰¥ 3.10 is installed.

Install the required packages directly with `pip`:

```bash
pip install torch torchvision torchaudio
pip install opencv-python albumentations pillow tqdm numpy pandas matplotlib scikit-learn
```

No virtual environment is required â€” these are standard PyPI packages only.

---
ğŸ“¦ Dataset: CUBS (Carotid Ultrasound B-mode Segmentation)

This project uses the CUBS dataset published on Mendeley Data
.

ğŸ”— Download Instructions

Go to the dataset page:
ğŸ‘‰ https://data.mendeley.com/datasets/fpv535fss7/1

Click the "Download All Files" button on the right side.
This will download a .zip file (â‰ˆ several hundred MB).

Extract the archive anywhere, for example:

C:\Users\<username>\Desktop\CUBS


The extracted folder should contain:

CUBS/
â”œâ”€â”€ IMAGES/
â”‚   â”œâ”€â”€ *.tif / *.tiff (ultrasound images)
â”œâ”€â”€ SEGMENTATIONS/
â”‚   â”œâ”€â”€ Manual-A1/
â”‚   â”‚   â”œâ”€â”€ *-LI.txt
â”‚   â”‚   â”œâ”€â”€ *-MA.txt

ğŸ§° Preprocessing Before Training

Run the preprocessing script to generate masks, standardize images (CLAHE), verify data, and split into train/val/test:

python preprocess_full.py --base_dir "C:\Users\<username>\Desktop\CUBS" --annotator "Manual-A1"


This will automatically create:

CUBS/
â””â”€â”€ data_std/
    â”œâ”€â”€ images/
    â”œâ”€â”€ masks/
    â”œâ”€â”€ train/
    â”œâ”€â”€ val/
    â”œâ”€â”€ test/
## ğŸ§® 2. Dataset Preprocessing

Place your dataset in the following structure:

```
CUBS/
 â”œâ”€ IMAGES/
 â””â”€ SEGMENTATIONS/Manual-A1/
```

Run the preprocessing pipeline:

```bash
python preprocess_full.py --base_dir CUBS --annotator Manual-A1
```

This will automatically:

1. Generate mask PNGs from LI/MA boundary text files  
2. Apply CLAHE (contrast enhancement)  
3. Verify imageâ€“mask shape consistency  
4. Split into `train`, `val`, and `test` subsets (6 : 2 : 2)

Output structure:

```
CUBS/data_std/
 â”œâ”€ train/
 â”œâ”€ val/
 â”œâ”€ test/
 â””â”€ split_summary.json
```

---

## ğŸš€ 3. Train Models

Run training interactively from the command line:

```bash
python train.py
```

Example prompt:

```
==============================
 CIMT Segmentation Training
==============================

Select models to train:
1. unet
2. unetpp
3. resunet
4. attention_unet
5. attention_resunet
6. seunet
7. denseunet
8. inceptionunet
9. transunet
10. unext

ğŸ’¡ Example:
 - Comma separated: 1,4,9
 - Range selection: 1-10 (means all models)

Enter model indices: 1-10
Enter number of epochs (default=100): 2
```

Training results are saved to:

```
results/
 â”œâ”€ [model_name]/best_model.pth
 â”œâ”€ [model_name]/final_model.pt
 â”œâ”€ [model_name]/train_log.csv
 â””â”€ summary.csv
```

---

## ğŸ¨ 4. Visualization

After training, visualize model predictions and overlays:

```bash
python visual_test.py
```

The script loads the trained model and saves visualization triplets (`Input`, `Ground Truth`, `Prediction`) under:

```
results/vis_[model_name]/
```

Each output shows:
- Left â†’ original ultrasound image  
- Middle â†’ ground-truth segmentation  
- Right â†’ predicted overlay

---

## ğŸ§¾ 5. Independent Script Usage

| Task | Command |
|------|----------|
| Run preprocessing only | `python preprocess_full.py --base_dir CUBS` |
| Train one or multiple models | `python train.py` |
| Generate visualization outputs | `python visual_test.py` |

All scripts are fully self-contained; no external configs or notebooks are required.

---

## ğŸ§  Models Implemented

| Type | Model | Description |
|------|--------|-------------|
| Base | **U-Net** | Standard encoderâ€“decoder |
| Nested | **U-Net++** | Dense skip connections |
| Residual | **ResU-Net** | Residual convolution blocks |
| Attention | **Attention U-Net** | Spatial attention in skip paths |
| Hybrid | **Attention ResU-Net** | Residual + attention mechanism |
| Squeeze | **SE-U-Net** | Channel attention (Squeeze-Excitation) |
| Dense | **DenseU-Net** | Dense connections per block |
| Inception | **Inception U-Net** | Multi-scale inception features |
| Transformer | **TransU-Net** | CNN + Transformer encoder |
| Lightweight | **UNeXt** | Efficient MLP-based segmentation |

---

## ğŸ“Š Evaluation Metrics

Each epoch logs the following:

- Binary Cross-Entropy (BCE) + Dice hybrid loss  
- Dice Coefficient  
- Intersection over Union (IoU)  
- Precision / Recall  
- Accuracy  
- Runtime per epoch and inference time

All values are recorded in `train_log.csv` and summarized in `results/summary.csv`.

---

## ğŸ’¡ Notes

- To adjust dataset path, edit `DATA_ROOT` in **train.py**:  
  ```python
  DATA_ROOT = Path("CUBS/data_std")
  ```
- To reduce memory usage:  
  ```python
  BATCH_SIZE = 4
  ```
- All `.pth` files are standard PyTorch checkpoints, compatible with both CPU and GPU.

---

## ğŸ Quick Command Summary

| Step | Command | Description |
|------|----------|-------------|
| 1ï¸âƒ£ Preprocess | `python preprocess_full.py --base_dir CUBS` | Prepare dataset |
| 2ï¸âƒ£ Train | `python train.py` | Train selected models |
| 3ï¸âƒ£ Visualize | `python visual_test.py` | Save overlay results |

---

## ğŸ§¾ License

Released under the **MIT License**.  
Use freely for research, education, and development.
